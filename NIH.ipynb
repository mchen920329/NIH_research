{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0739000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DOB_YY  DOB_MM  DOB_TT  DOB_WK  BFACIL  BFACIL3  MAGE_IMPFLG  MAGE_REPFLG  \\\n",
      "0    2018       1    1227       2       1        1         <NA>         <NA>   \n",
      "1    2018       1    1704       2       1        1         <NA>         <NA>   \n",
      "2    2018       1     336       2       1        1         <NA>         <NA>   \n",
      "3    2018       1     938       2       1        1         <NA>         <NA>   \n",
      "4    2018       1     830       3       1        1         <NA>         <NA>   \n",
      "5    2018       1      28       2       2        2         <NA>         <NA>   \n",
      "6    2018       1     341       3       1        1         <NA>         <NA>   \n",
      "7    2018       1    1615       4       1        1         <NA>         <NA>   \n",
      "8    2018       1    1754       5       1        1         <NA>         <NA>   \n",
      "9    2018       1    1111       6       1        1         <NA>         <NA>   \n",
      "\n",
      "   MAGER  MAGER14  ...  F_CA_CLEFTLP  F_CA_CLEFT  F_CA_DOWNS  F_CA_CHROM  \\\n",
      "0     30       10  ...             1           1           1           1   \n",
      "1     35       11  ...             1           1           1           1   \n",
      "2     28        9  ...             1           1           1           1   \n",
      "3     23        8  ...             1           1           1           1   \n",
      "4     37       11  ...             1           1           1           1   \n",
      "5     26        9  ...             1           1           1           1   \n",
      "6     28        9  ...             1           1           1           1   \n",
      "7     31       10  ...             1           1           1           1   \n",
      "8     37       11  ...             1           1           1           1   \n",
      "9     26        9  ...             1           1           1           1   \n",
      "\n",
      "   F_CA_HYPOS  NO_CONGEN  ITRAN  ILIVE  BFED  F_BFED  \n",
      "0           1          1   <NA>   <NA>  <NA>       1  \n",
      "1           1          1   <NA>   <NA>  <NA>       1  \n",
      "2           1          1   <NA>   <NA>  <NA>       1  \n",
      "3           1          1   <NA>   <NA>  <NA>       1  \n",
      "4           1          1   <NA>   <NA>  <NA>       1  \n",
      "5           1          1   <NA>   <NA>  <NA>       1  \n",
      "6           1          1   <NA>   <NA>  <NA>       1  \n",
      "7           1          1   <NA>   <NA>  <NA>       1  \n",
      "8           1          1   <NA>   <NA>  <NA>       1  \n",
      "9           1          1   <NA>   <NA>  <NA>       1  \n",
      "\n",
      "[10 rows x 227 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---- 路径：改成你的实际路径 ----\n",
    "file_path = \"/Users/muyuanchen/Desktop/Nat2018PublicUS.c20190509.r20190717.txt\"\n",
    "\n",
    "# =====================================================================\n",
    "# 1-based（包含右端） → 0-based 半开区间 (start-1, end)\n",
    "# 已含之前所有页到 ILLB_R，并修正 ILLB_R；再新增本页 5 个变量\n",
    "# 同时修正：MRACE6 仅 1 位；MRACE31 列名拼写\n",
    "# =====================================================================\n",
    "colspecs = [\n",
    "    # 出生基本信息\n",
    "    (8, 12),    # DOB_YY  (9–12)\n",
    "    (12, 14),   # DOB_MM  (13–14)\n",
    "    (18, 22),   # DOB_TT  (19–22)\n",
    "    (22, 23),   # DOB_WK  (23)\n",
    "    (31, 32),   # BFACIL  (32)\n",
    "    (49, 50),   # BFACIL3 (50)\n",
    "\n",
    "    # 母亲年龄\n",
    "    (72, 73),   # MAGE_IMPFLG (73)\n",
    "    (73, 74),   # MAGE_REPFLG (74)\n",
    "    (74, 76),   # MAGER      (75–76)\n",
    "    (76, 78),   # MAGER14    (77–78)\n",
    "    (78, 79),   # MAGER9     (79)\n",
    "\n",
    "    # 母亲国籍/居住/种族\n",
    "    (83, 84),   # MBSTATE_REC (84)\n",
    "    (103,104),  # RESTATUS    (104)\n",
    "    (104,106),  # MRACE31     (105–106)\n",
    "    (106,107),  # MRACE6      (107)\n",
    "    (108,110),  # MRACE15     (108–109)\n",
    "    (109,110),  # MBRACE      (110)\n",
    "    (110,111),  # MRACEIMP    (111)\n",
    "\n",
    "    # 母亲族裔\n",
    "    (111,112),  # MHISPX    (112)\n",
    "    (114,115),  # MHISP_R   (115)\n",
    "    (115,116),  # F_MHISP   (116)\n",
    "    (116,117),  # MRACEHISP (117)\n",
    "\n",
    "    # 婚姻状况 / 父系报告\n",
    "    (118,119),  # MAR_P   (119)\n",
    "    (119,120),  # DMAR    (120)\n",
    "    (120,121),  # MAR_IMP (121)\n",
    "    (122,123),  # F_MAR_P (123)\n",
    "\n",
    "    # 教育（母/父）\n",
    "    (123,124),  # MEDUC      (124)\n",
    "    (125,126),  # F_MEDUC    (126)\n",
    "    (141,142),  # FAGERPT_FLG (142)\n",
    "    (146,148),  # FAGECOMB    (147–148)\n",
    "    (148,150),  # FAGEREC11   (149–150)\n",
    "    (150,152),  # FRACE31     (151–152)\n",
    "    (152,153),  # FRACE6      (153)\n",
    "    (153,155),  # FRACE15     (154–155)\n",
    "    (158,159),  # FHISPX      (159)\n",
    "    (159,160),  # FHISP_R     (160)\n",
    "    (160,161),  # F_FHISP     (161)\n",
    "    (161,162),  # FRACEHISP   (162)\n",
    "    (162,163),  # FEDUC       (163)\n",
    "    (164,165),  # F_FEDUC     (165)\n",
    "\n",
    "    # 既往妊娠史\n",
    "    (170,172),  # PRIORLIVE (171–172)\n",
    "    (172,174),  # PRIORDEAD (173–174)\n",
    "    (174,176),  # PRIORTERM (175–176)\n",
    "    (178,179),  # LBO_REC   (179)\n",
    "    (181,182),  # TBO_REC   (182)\n",
    "\n",
    "    # 间隔 Recode\n",
    "    (197,200),  # ILLB_R   (198–200)\n",
    "    (200,202),  # ILLB_R11 (201–202)\n",
    "    (205,208),  # ILOP_R   (206–208)\n",
    "    (208,210),  # ILOP_R11 (209–210)\n",
    "    (213,216),  # ILP_R    (214–216)\n",
    "    (216,218),  # ILP_R11  (217–218)\n",
    "\n",
    "    # 产前检查\n",
    "    (223,225),  # PRECARE    (224–225)\n",
    "    (225,226),  # F_MPCB     (226)\n",
    "    (226,227),  # PRECARE5   (227)\n",
    "    (237,239),  # PREVIS     (238–239)\n",
    "    (241,243),  # PREVIS_REC (242–243)\n",
    "    (243,244),  # F_TPCV     (244)\n",
    "\n",
    "    # WIC & 吸烟\n",
    "    (250,251),  # WIC     (251)\n",
    "    (251,252),  # F_WIC   (252)\n",
    "    (252,254),  # CIG_0   (253–254)\n",
    "    (254,256),  # CIG_1   (255–256)\n",
    "    (256,258),  # CIG_2   (257–258)\n",
    "    (258,260),  # CIG_3   (259–260)\n",
    "    (260,261),  # CIG0_R  (261)\n",
    "    (261,262),  # CIG1_R  (262)\n",
    "    (262,263),  # CIG2_R  (263)\n",
    "    (263,264),  # CIG3_R  (264)\n",
    "    (264,265),  # F_CIGS_0 (265)\n",
    "    (265,266),  # F_CIGS_1 (266)\n",
    "    (266,267),  # F_CIGS_2 (267)\n",
    "    (267,268),  # F_CIGS_3 (268)\n",
    "    (268,269),  # CIG_REC  (269)\n",
    "    (269,270),  # F_TOBACO (270)\n",
    "\n",
    "    # 母亲身高 / BMI\n",
    "    (279,281),  # M_HT_IN (280–281)\n",
    "    (281,282),  # F_M_HT  (282)\n",
    "    (282,286),  # BMI     (283–286)\n",
    "    (286,287),  # BMI_R     (287) Body Mass Index Recode\n",
    "    # 288–291 FILLER 跳过\n",
    "    (291,294),  # PWGT_R    (292–294) Pre-pregnancy Weight Recode\n",
    "    (294,295),  # F_PWGT    (295) Reporting Flag for Pre-pregnancy Weight\n",
    "    # 296–298 FILLER 跳过\n",
    "    (298,301),  # DWGT_R    (299–301) Delivery Weight Recode\n",
    "    # 302 FILLER 跳过\n",
    "    (302,303),  # F_DWGT    (303) Reporting Flag for Delivery Weight\n",
    "    (303,305),  # WTGAIN    (304–305) Weight Gain\n",
    "    (305,306),  # WTGAIN_REC (306) Weight Gain Recode\n",
    "    (306,307),  # F_WTGAIN  (307) Reporting Flag for Weight Gain\n",
    "    # 308–312 FILLER 跳过\n",
    "    (312,313),  # RF_PDIAB   (313) Pre-pregnancy Diabetes\n",
    "    (313,314),  # RF_GDIAB   (314) Gestational Diabetes\n",
    "    (314,315),  # RF_PHYPE   (315) Pre-pregnancy Hypertension\n",
    "    (315,316),  # RF_GHYPE   (316) Gestational Hypertension\n",
    "    (316,317),  # RF_EHYPE   (317) Hypertension Eclampsia\n",
    "    (317,318),  # RF_PPTTERM (318) Previous Preterm Birth\n",
    "    (318,319),  # F_RF_PDIAB (319) Reporting Flag for Pre-pregnancy Diabetes\n",
    "    (319,320),  # F_RF_GDIAB (320) Reporting Flag for Gestational Diabetes\n",
    "    (320,321),  # F_RF_PHYPER (321) Reporting Flag for Pre-pregnancy Hypertension\n",
    "    (321,322),  # F_RF_GHYPER (322) Reporting Flag for Gestational Hypertension\n",
    "    (322,323),  # F_RF_ECLAMP (323) Reporting Flag for Hypertension Eclampsia\n",
    "    (323,324),  # F_RF_PPB   (324) Reporting Flag for Previous Preterm Birth\n",
    "    (324,325),  # RF_INFTR   (325) Infertility Treatment Used\n",
    "    (325,326),  # RF_FEDRG    (326) Fertility Enhancing Drugs\n",
    "    (326,327),  # RF_ARTEC    (327) Assisted Reproductive Technology\n",
    "    (327,328),  # F_RF_INFT   (328) Reporting Flag for Infertility Treatment\n",
    "    (328,329),  # F_RF_INF_DRG (329) Reporting Flag for Fertility Enhance Drugs\n",
    "    (329,330),  # F_RF_INF_ART (330) Reporting Flag for Reproductive Technology\n",
    "    (330,331),  # RF_CESAR    (331) Previous Cesarean\n",
    "    (331,333),  # RF_CESARN   (332–333) Number of Previous Cesareans\n",
    "    # 334 filler 跳过\n",
    "    (334,335),  # F_RF_CESAR  (335) Reporting Flag for Previous Cesarean\n",
    "    (335,336),  # F_RF_NCESAR (336) Reporting Flag for Number of Previous Cesareans\n",
    "    (336,337),\n",
    "    (342,343),  # IP_GON     (343) Gonorrhea\n",
    "    (343,344),  # IP_SYPH    (344) Syphilis\n",
    "    (344,345),  # IP_CHLAM   (345) Chlamydia\n",
    "    (345,346),  # IP_HEPB    (346) Hepatitis B\n",
    "    (346,347),  # IP_HEPC    (347) Hepatitis C\n",
    "    (347,348),  # F_IP_GONOR (348) Reporting Flag for Gonorrhea\n",
    "    (348,349),  # F_IP_SYPH  (349) Reporting Flag for Syphilis\n",
    "    (349,350),  # F_IP_CHLAM (350) Reporting Flag for Chlamydia\n",
    "    (350,351),  # F_IP_HEPATB (351) Reporting Flag for Hepatitis B\n",
    "    (351,352),  # F_IP_HEPATC (352) Reporting Flag for Hepatitis C\n",
    "    (352,353),  # NO_INFEC   (353) No Infections Reported\n",
    "    # 354–358 filler 跳过\n",
    "    (359,360),  # OB_ECVS   (360) Successful External Cephalic Version\n",
    "    (360,361),  # OB_ECVF   (361) Failed External Cephalic Version\n",
    "    # 362 filler 跳过\n",
    "    (362,363),  # F_OB_SUCC (363) Reporting Flag for Successful External Cephalic Version\n",
    "    (363,364),  # F_OB_FAIL (364) Reporting Flag for Failed External Cephalic Version\n",
    "    # 365–382 filler 跳过\n",
    "    (382,383),  # LD_INDL   (383) Induction of Labor\n",
    "    (383,384),  # LD_AUGM   (384) Augmentation of Labor\n",
    "    (384,385),  # LD_STER   (385) Steroids\n",
    "    (385,386),  # LD_ANTB   (386) Antibiotics\n",
    "    (386,387),  # LD_CHOR   (387) Chorioamnionitis\n",
    "    (387,388),  # LD_ANES    (388) Anesthesia\n",
    "    (388,389),  # F_LD_INDL  (389) Reporting Flag for Induction of Labor\n",
    "    (389,390),  # F_LD_AUGM  (390) Reporting Flag for Augmentation of Labor\n",
    "    (390,391),  # F_LD_STER  (391) Reporting Flag for Steroids\n",
    "    (391,392),  # F_LD_ANTB  (392) Reporting Flag for Antibiotics\n",
    "    (392,393),  # F_LD_CHOR  (393) Reporting Flag for Chorioamnionitis\n",
    "    (393,394),  # F_LD_ANES  (394) Reporting Flag for Anesthesia\n",
    "    (394,395),  # NO_LBRDLV  (395) No Characteristics of Labor Reported\n",
    "    # 396–400 filler 跳过\n",
    "    (400,401),  # ME_PRES    (401) Fetal Presentation at Delivery\n",
    "    (401,402),  # ME_ROUT    (402) Final Route & Method of Delivery\n",
    "    (402,403),  # ME_TRIAL   (403) Trial of Labor Attempted (if cesarean)\n",
    "    (403,404),  # F_ME_PRES    (404) Reporting Flag for Fetal Presentation\n",
    "    (404,405),  # F_ME_ROUT    (405) Reporting Flag for Final Route & Method of Delivery\n",
    "    (405,406),  # F_ME_TRIAL   (406) Reporting Flag for Trial of Labor Attempted\n",
    "    (406,407),  # RDMETH_REC   (407) Delivery Method Recode (detailed)\n",
    "    (407,408),  # DMETH_REC    (408) Delivery Method Recode (simple: vaginal / C-section / unknown)\n",
    "    (408,409),  # F_DMETH_REC  (409) Reporting Flag for Method of Delivery Recode\n",
    "    # 410–414 filler 跳过\n",
    "    (414,415),  # MM_MTR       (415) Maternal Transfusion\n",
    "    (415,416),  # MM_PLAC      (416) Perineal Laceration\n",
    "    (416,417),  # MM_RUPT      (417) Ruptured Uterus\n",
    "    (417,418),  # MM_UHYST     (418) Unplanned Hysterectomy\n",
    "    (418,419),  # MM_AICU    (419) Admit to Intensive Care\n",
    "    # 420 filler 跳过\n",
    "    (420,421),  # F_MM_MTR   (421) Reporting Flag for Maternal Transfusion\n",
    "    (421,422),  # F_MM_PLAC  (422) Reporting Flag for Perineal Laceration\n",
    "    (422,423),  # F_MM_RUPT  (423) Reporting Flag for Ruptured Uterus\n",
    "    (423,424),  # F_MM_UHYST (424) Reporting Flag for Unplanned Hysterectomy\n",
    "    (424,425),  # F_MM_AICU  (425) Reporting Flag for Admission to Intensive Care\n",
    "    # 426 filler 跳过\n",
    "    (426,427),  # NO_MMORB   (427) No Maternal Morbidity Reported\n",
    "    # 428–432 filler 跳过\n",
    "    (432,433),  # ATTEND     (433) Attendant at Birth\n",
    "    (433,434),  # MITRAN     (434) Mother Transferred\n",
    "    (434,435),  # PAY        (435) Payment Source for Delivery\n",
    "    # === 本页继续（436–450）: Payment Recode + APGAR ===\n",
    "    (435,436),  # PAY_REC   (436) Payment Recode\n",
    "    (436,437),  # F_PAY     (437) Reporting Flag for Source of Payment\n",
    "    (437,438),  # F_PAY_REC (438) Reporting Flag for Payment Recode\n",
    "    # 439–443 filler 跳过\n",
    "    (443,445),  # APGAR5    (444–445) Five Minute APGAR Score\n",
    "    (445,446),  # APGAR5R   (446) Five Minute APGAR Recode\n",
    "    (446,447),  # F_APGAR5  (447) Reporting Flag for Five Minute APGAR\n",
    "    (447,449),  # APGAR10   (448–449) Ten Minute APGAR Score\n",
    "    (449,450),  # APGAR10R  (450) Ten Minute APGAR Recode\n",
    "    # 451–453 filler 跳过\n",
    "    (453,454),  # DPLURAL   (454) Plurality Recode\n",
    "    # 455 filler 跳过\n",
    "    (455,456),  # IMP_PLUR  (456) Plurality Imputed\n",
    "    # 457–458 filler 跳过\n",
    "    (458,459),  # SETORDER_R (459) Set Order Recode\n",
    "    # 460–474 filler 跳过\n",
    "    (474,475),  # SEX       (475) Sex of Infant\n",
    "    (475,476),  # IMP_SEX   (476) Imputed Sex\n",
    "    (476,478),  # DLMP_MM   (477–478) Last Normal Menses Month\n",
    "    # 479–480 filler 跳过\n",
    "    (480,484),  # DLMP_YY    (481–484) Last Normal Menses Year\n",
    "    # 485–487 filler 跳过\n",
    "    (487,488),  # COMPGST_IMP (488) Combined Gestation Imputation Flag\n",
    "    (488,489),  # OBGEST_FLG  (489) Obstetric Estimate of Gestation Used Flag\n",
    "    (489,491),  # COMBGEST    (490–491) Combined Gestation – Detail in Weeks\n",
    "    (491,493),  # GESTREC10   (492–493) Combined Gestation Recode 10\n",
    "    (493,494),  # GESTREC3    (494) Combined Gestation Recode 3\n",
    "    # 495–497 filler 跳过\n",
    "    (497,498),  # LMPUSED     (498) Combined Gestation Used Flag\n",
    "    (498,500),  # OEGest_Comb (499–500) Obstetric Estimate Edited (weeks)\n",
    "    (500,502),  # OEGest_R10  (501–502) Obstetric Estimate Recode 10\n",
    "    # === 本页继续（503–518）: Birth Weight + Abnormal Newborn Conditions ===\n",
    "    (502,503),   # OEGest_R3 (503) Obstetric Estimate Recode 3\n",
    "    (503,507),   # DBWT      (504–507) Birth Weight – Detail in Grams (Edited)\n",
    "    # 508 filler 跳过\n",
    "    (508,510),   # BWTR12    (509–510) Birth Weight Recode 12\n",
    "    (510,511),   # BWTR4     (511) Birth Weight Recode 4\n",
    "    # 512–516 filler 跳过\n",
    "    (516,517),   # AB_AVEN1  (517) Assisted Ventilation (immediate)\n",
    "    (517,518),   # AB_AVEN6  (518) Assisted Ventilation > 6 hrs\n",
    "    # === 本页继续（519–531）: Abnormal Conditions of the Newborn ===\n",
    "    (518,519),  # AB_NICU    (519) Admission to NICU\n",
    "    (519,520),  # AB_SURF    (520) Surfactant\n",
    "    (520,521),  # AB_ANTI    (521) Antibiotics for Newborn\n",
    "    (521,522),  # AB_SEIZ    (522) Seizures\n",
    "    # 523 filler 跳过\n",
    "    (523,524),  # F_AB_VENT   (524) Reporting Flag for Assisted Ventilation (immediate)\n",
    "    (524,525),  # F_AB_VENT6  (525) Reporting Flag for Assisted Ventilation >6 hrs\n",
    "    (525,526),  # F_AB_NIUC   (526) Reporting Flag for Admission to NICU\n",
    "    (526,527),  # F_AB_SURFAC (527) Reporting Flag for Surfactant\n",
    "    (527,528),  # F_AB_ANTIBIO (528) Reporting Flag for Antibiotics\n",
    "    (528,529),  # F_AB_SEIZ   (529) Reporting Flag for Seizures\n",
    "    # 530 filler 跳过\n",
    "    (530,531),  # NO_ABNORM   (531) No Abnormal Conditions Checked\n",
    "    # 532–536 filler 跳过\n",
    "    (536,537),  # CA_ANEN   (537) Anencephaly\n",
    "    # === 本页继续（537–548）: Congenital Anomalies of the Newborn ===\n",
    "    (537,538),  # CA_MNSB   (538) Meningomyelocele / Spina Bifida\n",
    "    (538,539),  # CA_CCHD   (539) Cyanotic Congenital Heart Disease\n",
    "    (539,540),  # CA_CDH    (540) Congenital Diaphragmatic Hernia\n",
    "    (540,541),  # CA_OMPH   (541) Omphalocele\n",
    "    (541,542),  # CA_GAST   (542) Gastroschisis\n",
    "    (542,543),  # F_CA_ANEN  (543) Reporting Flag for Anencephaly\n",
    "    (543,544),  # F_CA_MENIN (544) Reporting Flag for Meningomyelocele/Spina Bifida\n",
    "    (544,545),  # F_CA_HEART (545) Reporting Flag for Congenital Heart Disease\n",
    "    (545,546),  # F_CA_HERNIA (546) Reporting Flag for Congenital Diaphragmatic Hernia\n",
    "    (546,547),  # F_CA_OMPHA  (547) Reporting Flag for Omphalocele\n",
    "    (547,548),  # F_CA_GASTRO (548) Reporting Flag for Gastroschisis\n",
    "    # === 本页继续（549–561）: Congenital Anomalies (continued) ===\n",
    "    (548,549),  # CA_LIMB    (549) Limb Reduction Defect\n",
    "    (549,550),  # CA_CLEFT   (550) Cleft Lip with/without Cleft Palate\n",
    "    (550,551),  # CA_CLPAL   (551) Cleft Palate alone\n",
    "    (551,552),  # CA_DOWN    (552) Down Syndrome\n",
    "    (552,553),  # CA_DISOR   (553) Suspected Chromosomal Disorder\n",
    "    (553,554),  # CA_HYPO    (554) Hypospadias\n",
    "    (554,555),  # F_CA_LIMB   (555) Reporting Flag for Limb Reduction Defect\n",
    "    (555,556),  # F_CA_CLEFTLP (556) Reporting Flag for Cleft Lip\n",
    "    (556,557),  # F_CA_CLEFT   (557) Reporting Flag for Cleft Palate\n",
    "    (557,558),  # F_CA_DOWNS   (558) Reporting Flag for Down Syndrome\n",
    "    (558,559),  # F_CA_CHROM   (559) Reporting Flag for Suspected Chromosomal Disorder\n",
    "    (559,560),  # F_CA_HYPOS   (560) Reporting Flag for Hypospadias\n",
    "    (560,561),  # NO_CONGEN    (561) No Congenital Anomalies Checked\n",
    "    # === 本页继续（567–570）: Infant Outcomes ===\n",
    "    (566,567),  # ITRAN   (567) Infant Transferred\n",
    "    (567,568),  # ILIVE   (568) Infant Living at Time of Report\n",
    "    (568,569),  # BFED    (569) Infant Breastfed at Discharge\n",
    "    (569,570),  # F_BFED  (570) Reporting Flag for Breastfed at Discharge\n",
    "    # 571–1330 filler 跳过\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "colnames = [\n",
    "    \"DOB_YY\",\"DOB_MM\",\"DOB_TT\",\"DOB_WK\",\"BFACIL\",\"BFACIL3\",\n",
    "    \"MAGE_IMPFLG\",\"MAGE_REPFLG\",\"MAGER\",\"MAGER14\",\"MAGER9\",\n",
    "    \"MBSTATE_REC\",\"RESTATUS\",\"MRACE31\",\"MRACE6\",\"MRACE15\",\"MBRACE\",\"MRACEIMP\",\n",
    "    \"MHISPX\",\"MHISP_R\",\"F_MHISP\",\"MRACEHISP\",\n",
    "    \"MAR_P\",\"DMAR\",\"MAR_IMP\",\"F_MAR_P\",\n",
    "    \"MEDUC\",\"F_MEDUC\",\"FAGERPT_FLG\",\"FAGECOMB\",\"FAGEREC11\",\"FRACE31\",\"FRACE6\",\"FRACE15\",\n",
    "    \"FHISPX\",\"FHISP_R\",\"F_FHISP\",\"FRACEHISP\",\"FEDUC\",\"F_FEDUC\",\n",
    "    \"PRIORLIVE\",\"PRIORDEAD\",\"PRIORTERM\",\"LBO_REC\",\"TBO_REC\",\n",
    "    \"ILLB_R\",\"ILLB_R11\",\"ILOP_R\",\"ILOP_R11\",\"ILP_R\",\"ILP_R11\",\n",
    "    \"PRECARE\",\"F_MPCB\",\"PRECARE5\",\"PREVIS\",\"PREVIS_REC\",\"F_TPCV\",\n",
    "    \"WIC\",\"F_WIC\",\"CIG_0\",\"CIG_1\",\"CIG_2\",\"CIG_3\",\n",
    "    \"CIG0_R\",\"CIG1_R\",\"CIG2_R\",\"CIG3_R\",\n",
    "    \"F_CIGS_0\",\"F_CIGS_1\",\"F_CIGS_2\",\"F_CIGS_3\",\n",
    "    \"CIG_REC\",\"F_TOBACO\",\n",
    "    \"M_HT_IN\",\"F_M_HT\",\"BMI\",\n",
    "    \"BMI_R\",\"PWGT_R\",\"F_PWGT\",\"DWGT_R\",\"F_DWGT\",\"WTGAIN\",\"WTGAIN_REC\",\"F_WTGAIN\",\n",
    "    \"RF_PDIAB\",\"RF_GDIAB\",\"RF_PHYPE\",\"RF_GHYPE\",\"RF_EHYPE\",\"RF_PPTTERM\",\n",
    "    \"F_RF_PDIAB\",\"F_RF_GDIAB\",\"F_RF_PHYPER\",\"F_RF_GHYPER\",\"F_RF_ECLAMP\",\"F_RF_PPB\",\n",
    "    \"RF_INFTR\",\n",
    "    \"RF_FEDRG\",\"RF_ARTEC\",\"F_RF_INFT\",\"F_RF_INF_DRG\",\"F_RF_INF_ART\",\n",
    "    \"RF_CESAR\",\"RF_CESARN\",\"F_RF_CESAR\",\"F_RF_NCESAR\",\"NO_RISKS\",\n",
    "    \"IP_GON\",\"IP_SYPH\",\"IP_CHLAM\",\"IP_HEPB\",\"IP_HEPC\",\n",
    "    \"F_IP_GONOR\",\"F_IP_SYPH\",\"F_IP_CHLAM\",\"F_IP_HEPATB\",\"F_IP_HEPATC\",\n",
    "    \"NO_INFEC\",\n",
    "    \"OB_ECVS\",\"OB_ECVF\",\"F_OB_SUCC\",\"F_OB_FAIL\",\n",
    "    \"LD_INDL\",\"LD_AUGM\",\"LD_STER\",\"LD_ANTB\",\"LD_CHOR\",\n",
    "    \"LD_ANES\",\n",
    "    \"F_LD_INDL\",\"F_LD_AUGM\",\"F_LD_STER\",\"F_LD_ANTB\",\"F_LD_CHOR\",\"F_LD_ANES\",\n",
    "    \"NO_LBRDLV\",\n",
    "    \"ME_PRES\",\"ME_ROUT\",\"ME_TRIAL\",\n",
    "    \"F_ME_PRES\",\"F_ME_ROUT\",\"F_ME_TRIAL\",\n",
    "    \"RDMETH_REC\",\"DMETH_REC\",\"F_DMETH_REC\",\n",
    "    \"MM_MTR\",\"MM_PLAC\",\"MM_RUPT\",\"MM_UHYST\",\n",
    "    \"MM_AICU\",\n",
    "    \"F_MM_MTR\",\"F_MM_PLAC\",\"F_MM_RUPT\",\"F_MM_UHYST\",\"F_MM_AICU\",\n",
    "    \"NO_MMORB\",\n",
    "    \"ATTEND\",\"MITRAN\",\"PAY\",\n",
    "    \"PAY_REC\",\"F_PAY\",\"F_PAY_REC\",\n",
    "    \"APGAR5\",\"APGAR5R\",\"F_APGAR5\",\"APGAR10\",\"APGAR10R\",\n",
    "    \"DPLURAL\",\"IMP_PLUR\",\"SETORDER_R\",\n",
    "    \"SEX\",\"IMP_SEX\",\"DLMP_MM\",\n",
    "    \"DLMP_YY\",\"COMPGST_IMP\",\"OBGEST_FLG\",\"COMBGEST\",\"GESTREC10\",\"GESTREC3\",\n",
    "    \"LMPUSED\",\"OEGest_Comb\",\"OEGest_R10\",\n",
    "    \"OEGest_R3\",\"DBWT\",\"BWTR12\",\"BWTR4\",\"AB_AVEN1\",\"AB_AVEN6\",\n",
    "    \"AB_NICU\",\"AB_SURF\",\"AB_ANTI\",\"AB_SEIZ\",\n",
    "    \"F_AB_VENT\",\"F_AB_VENT6\",\"F_AB_NIUC\",\"F_AB_SURFAC\",\"F_AB_ANTIBIO\",\"F_AB_SEIZ\",\n",
    "    \"NO_ABNORM\",\n",
    "    \"CA_ANEN\",\"CA_MNSB\",\"CA_CCHD\",\"CA_CDH\",\"CA_OMPH\",\"CA_GAST\",\n",
    "    \"F_CA_ANEN\",\"F_CA_MENIN\",\"F_CA_HEART\",\"F_CA_HERNIA\",\"F_CA_OMPHA\",\"F_CA_GASTRO\",\n",
    "    \"CA_LIMB\",\"CA_CLEFT\",\"CA_CLPAL\",\"CA_DOWN\",\"CA_DISOR\",\"CA_HYPO\",\n",
    "    \"F_CA_LIMB\",\"F_CA_CLEFTLP\",\"F_CA_CLEFT\",\"F_CA_DOWNS\",\"F_CA_CHROM\",\"F_CA_HYPOS\",\n",
    "    \"NO_CONGEN\",\n",
    "    \"ITRAN\",\"ILIVE\",\"BFED\",\"F_BFED\"\n",
    "]\n",
    "\n",
    "# ---- 读取前 10000 行，先按字符串读，避免空白自动变 NaN ----\n",
    "df_raw = pd.read_fwf(\n",
    "    file_path, colspecs=colspecs, names=colnames,\n",
    "    nrows=10000, dtype=\"string\", keep_default_na=False, na_filter=False\n",
    ")\n",
    "\n",
    "# 清理空格并尽量转数值（保留真正的空为 NaN）\n",
    "df = df_raw.apply(lambda s: s.str.strip())\n",
    "for c in colnames:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "print(df.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024447f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始列数: 227\n",
      "清理后列数: 168\n",
      "   DOB_YY  DOB_MM  DOB_TT  DOB_WK  BFACIL  BFACIL3  MAGER  MAGER14  MAGER9  \\\n",
      "0    2018       1    1227       2       1        1     30       10       5   \n",
      "1    2018       1    1704       2       1        1     35       11       6   \n",
      "2    2018       1     336       2       1        1     28        9       4   \n",
      "3    2018       1     938       2       1        1     23        8       3   \n",
      "4    2018       1     830       3       1        1     37       11       6   \n",
      "5    2018       1      28       2       2        2     26        9       4   \n",
      "6    2018       1     341       3       1        1     28        9       4   \n",
      "7    2018       1    1615       4       1        1     31       10       5   \n",
      "8    2018       1    1754       5       1        1     37       11       6   \n",
      "9    2018       1    1111       6       1        1     26        9       4   \n",
      "\n",
      "   MBSTATE_REC  ...  F_CA_OMPHA  F_CA_GASTRO  F_CA_LIMB  F_CA_CLEFTLP  \\\n",
      "0            1  ...           1            1          1             1   \n",
      "1            1  ...           1            1          1             1   \n",
      "2            1  ...           1            1          1             1   \n",
      "3            1  ...           1            1          1             1   \n",
      "4            1  ...           1            1          1             1   \n",
      "5            1  ...           1            1          1             1   \n",
      "6            1  ...           1            1          1             1   \n",
      "7            1  ...           1            1          1             1   \n",
      "8            2  ...           1            1          1             1   \n",
      "9            1  ...           1            1          1             1   \n",
      "\n",
      "   F_CA_CLEFT  F_CA_DOWNS  F_CA_CHROM  F_CA_HYPOS  NO_CONGEN  F_BFED  \n",
      "0           1           1           1           1          1       1  \n",
      "1           1           1           1           1          1       1  \n",
      "2           1           1           1           1          1       1  \n",
      "3           1           1           1           1          1       1  \n",
      "4           1           1           1           1          1       1  \n",
      "5           1           1           1           1          1       1  \n",
      "6           1           1           1           1          1       1  \n",
      "7           1           1           1           1          1       1  \n",
      "8           1           1           1           1          1       1  \n",
      "9           1           1           1           1          1       1  \n",
      "\n",
      "[10 rows x 168 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---- 假设你前面已经 parse 完成，得到 df ----\n",
    "# 这里 df 就是 pd.read_fwf(...) 读进来的 DataFrame\n",
    "\n",
    "# 删除所有全是 NaN 或空白的列\n",
    "import numpy as np\n",
    "\n",
    "# 把 <NA> 统一转成 np.nan\n",
    "import numpy as np\n",
    "\n",
    "df_clean = df.copy()\n",
    "# 统一把 <NA> 转成 np.nan\n",
    "df_clean = df_clean.replace({pd.NA: np.nan})\n",
    "\n",
    "# 去掉全是 nan/空格/空字符串的列\n",
    "df_clean = df_clean.loc[:, ~df_clean.replace(r'^\\s*$', np.nan, regex=True).isna().all(axis=0)]\n",
    "\n",
    "\n",
    "print(\"原始列数:\", df.shape[1])\n",
    "print(\"清理后列数:\", df_clean.shape[1])\n",
    "\n",
    "\n",
    "# 保存一下结果\n",
    "df_clean.to_csv(\"nat2018_clean.csv\", index=False)\n",
    "\n",
    "print(df_clean.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b00099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 使用数值列 165，类别列 0\n",
      "[INFO] PCA 主成分数: 50, 累计解释方差: 0.980\n",
      "[RESULT] PCA+Linear Regression → RMSE: 469.0 g | R²: 0.322\n",
      "[SANITY] y(mean±std)=3401.1±584.4, pred(min,max)=(1665.6, 6339.8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "import sklearn\n",
    "\n",
    "# ========= 0) 数据准备 =========\n",
    "df = df_clean.copy()\n",
    "df.columns = df.columns.str.lower()\n",
    "assert \"dbwt\" in df.columns, \"找不到 dbwt 列（出生体重）\"\n",
    "\n",
    "# 丢掉 y 缺失 & 明显异常\n",
    "df = df[df[\"dbwt\"].notna()].copy()\n",
    "df = df[(df[\"dbwt\"] >= 500) & (df[\"dbwt\"] <= 6000)].copy()\n",
    "\n",
    "# 强制移除派生泄漏列\n",
    "leak_cols = [\"bwtr12\", \"bwtr4\"]\n",
    "df = df.drop(columns=[c for c in leak_cols if c in df.columns])\n",
    "\n",
    "# 特征/目标\n",
    "X = df.drop(columns=[\"dbwt\"])\n",
    "y = df[\"dbwt\"].astype(float).values\n",
    "\n",
    "# 列类型划分\n",
    "num_cols = X.select_dtypes(include=\"number\").columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=\"number\").columns.tolist()\n",
    "print(f\"[INFO] 使用数值列 {len(num_cols)}，类别列 {len(cat_cols)}\")\n",
    "\n",
    "# ========= 1) 先切分，再在训练集上拟合（避免泄漏）=========\n",
    "Xtr_raw, Xva_raw, ytr, yva = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ========= 2) 预处理（数值：中位数填充+标准化；类别：众数填充+OneHot(稠密)）=========\n",
    "# sklearn 1.2+ 用 sparse_output；老版本用 sparse=False\n",
    "ohe_kwargs = {}\n",
    "ver = tuple(map(int, sklearn.__version__.split(\".\")[:2]))\n",
    "if ver >= (1, 2):\n",
    "    ohe_kwargs[\"sparse_output\"] = False\n",
    "else:\n",
    "    ohe_kwargs[\"sparse\"] = False\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", **ohe_kwargs))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "# ========= 3) PCA + Linear Regression ==========\n",
    "model = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"pca\", PCA(n_components=50, svd_solver=\"full\", random_state=42)),  # 或 n_components=0.95\n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "\n",
    "# ========= 4) 训练与评估 ==========\n",
    "model.fit(Xtr_raw, ytr)\n",
    "pred = model.predict(Xva_raw)\n",
    "\n",
    "rmse = root_mean_squared_error(yva, pred)\n",
    "r2 = r2_score(yva, pred)\n",
    "\n",
    "pca = model.named_steps[\"pca\"]\n",
    "expl = pca.explained_variance_ratio_.sum()\n",
    "print(f\"[INFO] PCA 主成分数: {pca.n_components_}, 累计解释方差: {expl:.3f}\")\n",
    "print(f\"[RESULT] PCA+Linear Regression → RMSE: {rmse:.1f} g | R²: {r2:.3f}\")\n",
    "print(f\"[SANITY] y(mean±std)={ytr.mean():.1f}±{ytr.std():.1f}, pred(min,max)=({pred.min():.1f}, {pred.max():.1f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65e39029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] device = cpu | sklearn: 1.4.2 | torch: 2.3.1\n",
      "[INFO] 使用数值列 165，类别列 0\n",
      "[SPLIT] train=6993 | val=1498 | test=1499\n",
      "[INFO] PCA 主成分数: 50 | 累计解释方差: 0.980\n",
      "PcaRegressor(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 001 | val_loss=0.60809 (std-y 尺度) | lr=0.000998\n",
      "Epoch 010 | val_loss=0.51391 (std-y 尺度) | lr=0.000998\n",
      "Epoch 020 | val_loss=0.51192 (std-y 尺度) | lr=0.000998\n",
      "Epoch 030 | val_loss=0.52739 (std-y 尺度) | lr=0.000998\n",
      "Epoch 040 | val_loss=0.53524 (std-y 尺度) | lr=0.000998\n",
      "[EarlyStopping] 第 40 轮触发 | 最佳验证损失=0.51192\n",
      "[VAL] RMSE: 417.8 g | R²: 0.463 | pred(min,max)=(302.5,4089.9)\n",
      "[TEST] RMSE: 432.5 g | R²: 0.448 | pred(min,max)=(612.0,4117.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 0) Imports & 全局设置\n",
    "# =========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"[INFO] device =\", device, \"| sklearn:\", sklearn.__version__, \"| torch:\", torch.__version__)\n",
    "\n",
    "# =========================================================\n",
    "# 1) 数据准备（以 df_clean 为源）\n",
    "# =========================================================\n",
    "df = df_clean.copy()\n",
    "df.columns = df.columns.str.lower()\n",
    "assert \"dbwt\" in df.columns, \"找不到 dbwt 列（出生体重，克）\"\n",
    "\n",
    "# 丢掉 y 缺失与异常\n",
    "df = df[df[\"dbwt\"].notna()].copy()\n",
    "df = df[(df[\"dbwt\"] >= 500) & (df[\"dbwt\"] <= 6000)].copy()\n",
    "\n",
    "# 移除潜在泄漏列（如果存在）\n",
    "leak_cols = [\"bwtr12\", \"bwtr4\"]\n",
    "df = df.drop(columns=[c for c in leak_cols if c in df.columns])\n",
    "\n",
    "# 特征与目标\n",
    "X = df.drop(columns=[\"dbwt\"])\n",
    "y = df[\"dbwt\"].astype(float).values\n",
    "\n",
    "# 列类型划分\n",
    "num_cols = X.select_dtypes(include=\"number\").columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=\"number\").columns.tolist()\n",
    "print(f\"[INFO] 使用数值列 {len(num_cols)}，类别列 {len(cat_cols)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 2) 三划分：train / val / test（回归用分箱伪分层）\n",
    "# =========================================================\n",
    "def make_strata(y, q=10):\n",
    "    try:\n",
    "        return pd.qcut(y, q=q, labels=False, duplicates=\"drop\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "strata = make_strata(y, q=10)\n",
    "\n",
    "# 70% train, 15% val, 15% test\n",
    "Xtr_raw, Xtemp, ytr, ytemp, strata_tr, strata_temp = train_test_split(\n",
    "    X, y, strata, test_size=0.30, random_state=42,\n",
    "    stratify=strata if strata is not None else None\n",
    ")\n",
    "\n",
    "Xva_raw, Xte_raw, yva, yte, strata_va, strata_te = train_test_split(\n",
    "    Xtemp, ytemp, strata_temp, test_size=0.50, random_state=42,\n",
    "    stratify=strata_temp if strata is not None else None\n",
    ")\n",
    "\n",
    "print(f\"[SPLIT] train={len(ytr)} | val={len(yva)} | test={len(yte)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 3) 预处理（数值：中位数填充+标准化；类别：众数填充+OneHot）\n",
    "# =========================================================\n",
    "ohe_kwargs = {}\n",
    "ver = tuple(map(int, sklearn.__version__.split(\".\")[:2]))\n",
    "if ver >= (1, 2):\n",
    "    ohe_kwargs[\"sparse_output\"] = False\n",
    "else:\n",
    "    ohe_kwargs[\"sparse\"] = False\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", **ohe_kwargs))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "# =========================================================\n",
    "# 4) PCA（只在训练集上 fit），n_components=150（可调或用 0.95）\n",
    "# =========================================================\n",
    "pca_dim_target = 50  # 你指定的维度；也可改为 0.95（保留95%方差）\n",
    "prep_pca = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"pca\", PCA(n_components=pca_dim_target, svd_solver=\"full\", random_state=42))\n",
    "])\n",
    "\n",
    "prep_pca.fit(Xtr_raw, ytr)\n",
    "Ztr = prep_pca.transform(Xtr_raw)\n",
    "Zva = prep_pca.transform(Xva_raw)\n",
    "Zte = prep_pca.transform(Xte_raw)\n",
    "\n",
    "pca = prep_pca.named_steps[\"pca\"]\n",
    "expl = pca.explained_variance_ratio_.sum()\n",
    "print(f\"[INFO] PCA 主成分数: {pca.n_components_} | 累计解释方差: {expl:.3f}\")\n",
    "\n",
    "# =========================================================\n",
    "# 5) 目标标准化（提升回归稳定性）\n",
    "# =========================================================\n",
    "y_mean, y_std = ytr.mean(), ytr.std()\n",
    "ytr_std = (ytr - y_mean) / y_std\n",
    "yva_std = (yva - y_mean) / y_std\n",
    "yte_std = (yte - y_mean) / y_std\n",
    "\n",
    "# =========================================================\n",
    "# 6) 张量与 DataLoader\n",
    "# =========================================================\n",
    "Xtr_t = torch.tensor(Ztr, dtype=torch.float32)\n",
    "Xva_t = torch.tensor(Zva, dtype=torch.float32)\n",
    "Xte_t = torch.tensor(Zte, dtype=torch.float32)\n",
    "\n",
    "ytr_t = torch.tensor(ytr_std, dtype=torch.float32).unsqueeze(1)\n",
    "yva_t = torch.tensor(yva_std, dtype=torch.float32).unsqueeze(1)\n",
    "yte_t = torch.tensor(yte_std, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(Xtr_t, ytr_t), batch_size=256, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(Xva_t, yva_t), batch_size=1024, shuffle=False)\n",
    "test_loader  = DataLoader(TensorDataset(Xte_t, yte_t), batch_size=1024, shuffle=False)\n",
    "\n",
    "# =========================================================\n",
    "# 7) 模型（两种二选一）——默认启用「简单版」\n",
    "# =========================================================\n",
    "USE_STRONG_RESIDUAL = False  # ← 想用更强的残差版就改为 True\n",
    "\n",
    "class PreNormResidual(nn.Module):\n",
    "    def __init__(self, dim, hidden, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ff1 = nn.Sequential(nn.Linear(dim, hidden), nn.SiLU(), nn.Dropout(dropout))\n",
    "        self.norm2 = nn.LayerNorm(hidden)\n",
    "        self.ff2 = nn.Linear(hidden, dim)\n",
    "    def forward(self, x):\n",
    "        h = self.ff1(self.norm1(x))\n",
    "        h = self.ff2(self.norm2(h))\n",
    "        return x + h\n",
    "\n",
    "class StrongRegressor(nn.Module):\n",
    "    def __init__(self, in_dim, width=256, depth=4, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.inp = nn.Sequential(nn.LayerNorm(in_dim), nn.Linear(in_dim, width), nn.SiLU())\n",
    "        self.blocks = nn.Sequential(*[PreNormResidual(width, width, dropout) for _ in range(depth)])\n",
    "        self.head = nn.Sequential(nn.LayerNorm(width), nn.Linear(width, width//2), nn.SiLU(), nn.Linear(width//2, 1))\n",
    "    def forward(self, x):\n",
    "        x = self.inp(x); x = self.blocks(x); return self.head(x)\n",
    "\n",
    "model = StrongRegressor(pca_dim_target).to(device)\n",
    "\n",
    "\n",
    "in_dim = Ztr.shape[1]\n",
    "if USE_STRONG_RESIDUAL:\n",
    "    model = StrongRegressor(in_dim=in_dim, width=256, depth=4, dropout=0.3).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=2e-5)\n",
    "    scheduler_mode = \"cosine\"\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2)\n",
    "else:\n",
    "    model = PcaRegressor(in_dim).to(device)\n",
    "    # 注意：你之前设置 lr=1e-1 偏大，容易不稳；这里用 1e-3 更靠谱\n",
    "    criterion = nn.MSELoss()                          # 更贴近 RMSE \n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=2e-5)\n",
    "\n",
    "    # 调度器：余弦退火 + warm restarts（代替 ReduceLROnPlateau）\n",
    "    from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2)\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n",
    "# =========================================================\n",
    "# 8) 训练循环（带 EarlyStopping）\n",
    "# =========================================================\n",
    "epochs = 300\n",
    "patience = 20\n",
    "best_val = float(\"inf\")\n",
    "best_state = None\n",
    "wait = 0\n",
    "\n",
    "def evaluate_avg_loss(loader):\n",
    "    model.eval()\n",
    "    loss_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            bs = xb.shape[0]\n",
    "            loss_sum += loss.item() * bs\n",
    "            n += bs\n",
    "    return loss_sum / max(n, 1)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    val_loss = evaluate_avg_loss(val_loader)\n",
    "\n",
    "    # 调度\n",
    "    if scheduler_mode == \"plateau\":\n",
    "        scheduler.step(val_loss)\n",
    "    else:\n",
    "        scheduler.step(epoch)\n",
    "\n",
    "    # 早停\n",
    "    if val_loss < best_val - 1e-6:\n",
    "        best_val = val_loss\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:03d} | val_loss={val_loss:.5f} (std-y 尺度) | lr={optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    if wait >= patience:\n",
    "        print(f\"[EarlyStopping] 第 {epoch} 轮触发 | 最佳验证损失={best_val:.5f}\")\n",
    "        break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "# =========================================================\n",
    "# 9) 评估：验证集与测试集（还原到克单位）\n",
    "# =========================================================\n",
    "def inv_std(y_std_arr):\n",
    "    return y_std_arr * y_std + y_mean\n",
    "\n",
    "def eval_rmse_r2(X_t, y_true, name=\"SPLIT\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_std = model(X_t.to(device)).cpu().numpy().ravel()\n",
    "    y_pred = inv_std(y_pred_std)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    print(f\"[{name}] RMSE: {rmse:.1f} g | R²: {r2:.3f} | pred(min,max)=({y_pred.min():.1f},{y_pred.max():.1f})\")\n",
    "    return rmse, r2\n",
    "\n",
    "_ = eval_rmse_r2(Xva_t, yva, name=\"VAL\")\n",
    "_ = eval_rmse_r2(Xte_t, yte, name=\"TEST\")\n",
    "\n",
    "# =========================================================\n",
    "# 10) 推理函数（新样本 DataFrame → 预测克重）\n",
    "# =========================================================\n",
    "def predict_dbwt_with_torch(df_new: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    输入：原始特征表 df_new（列需与训练时一致）\n",
    "    输出：预测出生体重（克）\n",
    "    \"\"\"\n",
    "    Z_new = prep_pca.transform(df_new)  # 预处理 + PCA\n",
    "    X_new = torch.tensor(Z_new, dtype=torch.float32).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_std = model(X_new).cpu().numpy().ravel()\n",
    "    return inv_std(y_pred_std)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
