{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9dcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---- è·¯å¾„ï¼šæ”¹æˆä½ çš„å®é™…è·¯å¾„ ----\n",
    "file_path = \"/Users/muyuanchen/Desktop/NIH_research/Nat2018PublicUS.c20190509.r20190717.txt\"\n",
    "\n",
    "# =====================================================================\n",
    "# 1-basedï¼ˆåŒ…å«å³ç«¯ï¼‰ â†’ 0-based åŠå¼€åŒºé—´ (start-1, end)\n",
    "# å·²å«ä¹‹å‰æ‰€æœ‰é¡µåˆ° ILLB_Rï¼Œå¹¶ä¿®æ­£ ILLB_Rï¼›å†æ–°å¢æœ¬é¡µ 5 ä¸ªå˜é‡\n",
    "# åŒæ—¶ä¿®æ­£ï¼šMRACE6 ä»… 1 ä½ï¼›MRACE31 åˆ—åæ‹¼å†™\n",
    "# =====================================================================\n",
    "colspecs = [\n",
    "    # å‡ºç”ŸåŸºæœ¬ä¿¡æ¯\n",
    "    (8, 12),    # DOB_YY  (9â€“12)\n",
    "    (12, 14),   # DOB_MM  (13â€“14)\n",
    "    (18, 22),   # DOB_TT  (19â€“22)\n",
    "    (22, 23),   # DOB_WK  (23)\n",
    "    (31, 32),   # BFACIL  (32)\n",
    "    (49, 50),   # BFACIL3 (50)\n",
    "\n",
    "    # æ¯äº²å¹´é¾„\n",
    "    (72, 73),   # MAGE_IMPFLG (73)\n",
    "    (73, 74),   # MAGE_REPFLG (74)\n",
    "    (74, 76),   # MAGER      (75â€“76)\n",
    "    (76, 78),   # MAGER14    (77â€“78)\n",
    "    (78, 79),   # MAGER9     (79)\n",
    "\n",
    "    # æ¯äº²å›½ç±/å±…ä½/ç§æ—\n",
    "    (83, 84),   # MBSTATE_REC (84)\n",
    "    (103,104),  # RESTATUS    (104)\n",
    "    (104,106),  # MRACE31     (105â€“106)\n",
    "    (106,107),  # MRACE6      (107)\n",
    "    (108,110),  # MRACE15     (108â€“109)\n",
    "    (109,110),  # MBRACE      (110)\n",
    "    (110,111),  # MRACEIMP    (111)\n",
    "\n",
    "    # æ¯äº²æ—è£”\n",
    "    (111,112),  # MHISPX    (112)\n",
    "    (114,115),  # MHISP_R   (115)\n",
    "    (115,116),  # F_MHISP   (116)\n",
    "    (116,117),  # MRACEHISP (117)\n",
    "\n",
    "    # å©šå§»çŠ¶å†µ / çˆ¶ç³»æŠ¥å‘Š\n",
    "    (118,119),  # MAR_P   (119)\n",
    "    (119,120),  # DMAR    (120)\n",
    "    (120,121),  # MAR_IMP (121)\n",
    "    (122,123),  # F_MAR_P (123)\n",
    "\n",
    "    # æ•™è‚²ï¼ˆæ¯/çˆ¶ï¼‰\n",
    "    (123,124),  # MEDUC      (124)\n",
    "    (125,126),  # F_MEDUC    (126)\n",
    "    (141,142),  # FAGERPT_FLG (142)\n",
    "    (146,148),  # FAGECOMB    (147â€“148)\n",
    "    (148,150),  # FAGEREC11   (149â€“150)\n",
    "    (150,152),  # FRACE31     (151â€“152)\n",
    "    (152,153),  # FRACE6      (153)\n",
    "    (153,155),  # FRACE15     (154â€“155)\n",
    "    (158,159),  # FHISPX      (159)\n",
    "    (159,160),  # FHISP_R     (160)\n",
    "    (160,161),  # F_FHISP     (161)\n",
    "    (161,162),  # FRACEHISP   (162)\n",
    "    (162,163),  # FEDUC       (163)\n",
    "    (164,165),  # F_FEDUC     (165)\n",
    "\n",
    "    # æ—¢å¾€å¦Šå¨ å²\n",
    "    (170,172),  # PRIORLIVE (171â€“172)\n",
    "    (172,174),  # PRIORDEAD (173â€“174)\n",
    "    (174,176),  # PRIORTERM (175â€“176)\n",
    "    (178,179),  # LBO_REC   (179)\n",
    "    (181,182),  # TBO_REC   (182)\n",
    "\n",
    "    # é—´éš” Recode\n",
    "    (197,200),  # ILLB_R   (198â€“200)\n",
    "    (200,202),  # ILLB_R11 (201â€“202)\n",
    "    (205,208),  # ILOP_R   (206â€“208)\n",
    "    (208,210),  # ILOP_R11 (209â€“210)\n",
    "    (213,216),  # ILP_R    (214â€“216)\n",
    "    (216,218),  # ILP_R11  (217â€“218)\n",
    "\n",
    "    # äº§å‰æ£€æŸ¥\n",
    "    (223,225),  # PRECARE    (224â€“225)\n",
    "    (225,226),  # F_MPCB     (226)\n",
    "    (226,227),  # PRECARE5   (227)\n",
    "    (237,239),  # PREVIS     (238â€“239)\n",
    "    (241,243),  # PREVIS_REC (242â€“243)\n",
    "    (243,244),  # F_TPCV     (244)\n",
    "\n",
    "    # WIC & å¸çƒŸ\n",
    "    (250,251),  # WIC     (251)\n",
    "    (251,252),  # F_WIC   (252)\n",
    "    (252,254),  # CIG_0   (253â€“254)\n",
    "    (254,256),  # CIG_1   (255â€“256)\n",
    "    (256,258),  # CIG_2   (257â€“258)\n",
    "    (258,260),  # CIG_3   (259â€“260)\n",
    "    (260,261),  # CIG0_R  (261)\n",
    "    (261,262),  # CIG1_R  (262)\n",
    "    (262,263),  # CIG2_R  (263)\n",
    "    (263,264),  # CIG3_R  (264)\n",
    "    (264,265),  # F_CIGS_0 (265)\n",
    "    (265,266),  # F_CIGS_1 (266)\n",
    "    (266,267),  # F_CIGS_2 (267)\n",
    "    (267,268),  # F_CIGS_3 (268)\n",
    "    (268,269),  # CIG_REC  (269)\n",
    "    (269,270),  # F_TOBACO (270)\n",
    "\n",
    "    # æ¯äº²èº«é«˜ / BMI\n",
    "    (279,281),  # M_HT_IN (280â€“281)\n",
    "    (281,282),  # F_M_HT  (282)\n",
    "    (282,286),  # BMI     (283â€“286)\n",
    "    (286,287),  # BMI_R     (287) Body Mass Index Recode\n",
    "    # 288â€“291 FILLER è·³è¿‡\n",
    "    (291,294),  # PWGT_R    (292â€“294) Pre-pregnancy Weight Recode\n",
    "    (294,295),  # F_PWGT    (295) Reporting Flag for Pre-pregnancy Weight\n",
    "    # 296â€“298 FILLER è·³è¿‡\n",
    "    (298,301),  # DWGT_R    (299â€“301) Delivery Weight Recode\n",
    "    # 302 FILLER è·³è¿‡\n",
    "    (302,303),  # F_DWGT    (303) Reporting Flag for Delivery Weight\n",
    "    (303,305),  # WTGAIN    (304â€“305) Weight Gain\n",
    "    (305,306),  # WTGAIN_REC (306) Weight Gain Recode\n",
    "    (306,307),  # F_WTGAIN  (307) Reporting Flag for Weight Gain\n",
    "    # 308â€“312 FILLER è·³è¿‡\n",
    "    (312,313),  # RF_PDIAB   (313) Pre-pregnancy Diabetes\n",
    "    (313,314),  # RF_GDIAB   (314) Gestational Diabetes\n",
    "    (314,315),  # RF_PHYPE   (315) Pre-pregnancy Hypertension\n",
    "    (315,316),  # RF_GHYPE   (316) Gestational Hypertension\n",
    "    (316,317),  # RF_EHYPE   (317) Hypertension Eclampsia\n",
    "    (317,318),  # RF_PPTTERM (318) Previous Preterm Birth\n",
    "    (318,319),  # F_RF_PDIAB (319) Reporting Flag for Pre-pregnancy Diabetes\n",
    "    (319,320),  # F_RF_GDIAB (320) Reporting Flag for Gestational Diabetes\n",
    "    (320,321),  # F_RF_PHYPER (321) Reporting Flag for Pre-pregnancy Hypertension\n",
    "    (321,322),  # F_RF_GHYPER (322) Reporting Flag for Gestational Hypertension\n",
    "    (322,323),  # F_RF_ECLAMP (323) Reporting Flag for Hypertension Eclampsia\n",
    "    (323,324),  # F_RF_PPB   (324) Reporting Flag for Previous Preterm Birth\n",
    "    (324,325),  # RF_INFTR   (325) Infertility Treatment Used\n",
    "    (325,326),  # RF_FEDRG    (326) Fertility Enhancing Drugs\n",
    "    (326,327),  # RF_ARTEC    (327) Assisted Reproductive Technology\n",
    "    (327,328),  # F_RF_INFT   (328) Reporting Flag for Infertility Treatment\n",
    "    (328,329),  # F_RF_INF_DRG (329) Reporting Flag for Fertility Enhance Drugs\n",
    "    (329,330),  # F_RF_INF_ART (330) Reporting Flag for Reproductive Technology\n",
    "    (330,331),  # RF_CESAR    (331) Previous Cesarean\n",
    "    (331,333),  # RF_CESARN   (332â€“333) Number of Previous Cesareans\n",
    "    # 334 filler è·³è¿‡\n",
    "    (334,335),  # F_RF_CESAR  (335) Reporting Flag for Previous Cesarean\n",
    "    (335,336),  # F_RF_NCESAR (336) Reporting Flag for Number of Previous Cesareans\n",
    "    (336,337),\n",
    "    (342,343),  # IP_GON     (343) Gonorrhea\n",
    "    (343,344),  # IP_SYPH    (344) Syphilis\n",
    "    (344,345),  # IP_CHLAM   (345) Chlamydia\n",
    "    (345,346),  # IP_HEPB    (346) Hepatitis B\n",
    "    (346,347),  # IP_HEPC    (347) Hepatitis C\n",
    "    (347,348),  # F_IP_GONOR (348) Reporting Flag for Gonorrhea\n",
    "    (348,349),  # F_IP_SYPH  (349) Reporting Flag for Syphilis\n",
    "    (349,350),  # F_IP_CHLAM (350) Reporting Flag for Chlamydia\n",
    "    (350,351),  # F_IP_HEPATB (351) Reporting Flag for Hepatitis B\n",
    "    (351,352),  # F_IP_HEPATC (352) Reporting Flag for Hepatitis C\n",
    "    (352,353),  # NO_INFEC   (353) No Infections Reported\n",
    "    # 354â€“358 filler è·³è¿‡\n",
    "    (359,360),  # OB_ECVS   (360) Successful External Cephalic Version\n",
    "    (360,361),  # OB_ECVF   (361) Failed External Cephalic Version\n",
    "    # 362 filler è·³è¿‡\n",
    "    (362,363),  # F_OB_SUCC (363) Reporting Flag for Successful External Cephalic Version\n",
    "    (363,364),  # F_OB_FAIL (364) Reporting Flag for Failed External Cephalic Version\n",
    "    # 365â€“382 filler è·³è¿‡\n",
    "    (382,383),  # LD_INDL   (383) Induction of Labor\n",
    "    (383,384),  # LD_AUGM   (384) Augmentation of Labor\n",
    "    (384,385),  # LD_STER   (385) Steroids\n",
    "    (385,386),  # LD_ANTB   (386) Antibiotics\n",
    "    (386,387),  # LD_CHOR   (387) Chorioamnionitis\n",
    "    (387,388),  # LD_ANES    (388) Anesthesia\n",
    "    (388,389),  # F_LD_INDL  (389) Reporting Flag for Induction of Labor\n",
    "    (389,390),  # F_LD_AUGM  (390) Reporting Flag for Augmentation of Labor\n",
    "    (390,391),  # F_LD_STER  (391) Reporting Flag for Steroids\n",
    "    (391,392),  # F_LD_ANTB  (392) Reporting Flag for Antibiotics\n",
    "    (392,393),  # F_LD_CHOR  (393) Reporting Flag for Chorioamnionitis\n",
    "    (393,394),  # F_LD_ANES  (394) Reporting Flag for Anesthesia\n",
    "    (394,395),  # NO_LBRDLV  (395) No Characteristics of Labor Reported\n",
    "    # 396â€“400 filler è·³è¿‡\n",
    "    (400,401),  # ME_PRES    (401) Fetal Presentation at Delivery\n",
    "    (401,402),  # ME_ROUT    (402) Final Route & Method of Delivery\n",
    "    (402,403),  # ME_TRIAL   (403) Trial of Labor Attempted (if cesarean)\n",
    "    (403,404),  # F_ME_PRES    (404) Reporting Flag for Fetal Presentation\n",
    "    (404,405),  # F_ME_ROUT    (405) Reporting Flag for Final Route & Method of Delivery\n",
    "    (405,406),  # F_ME_TRIAL   (406) Reporting Flag for Trial of Labor Attempted\n",
    "    (406,407),  # RDMETH_REC   (407) Delivery Method Recode (detailed)\n",
    "    (407,408),  # DMETH_REC    (408) Delivery Method Recode (simple: vaginal / C-section / unknown)\n",
    "    (408,409),  # F_DMETH_REC  (409) Reporting Flag for Method of Delivery Recode\n",
    "    # 410â€“414 filler è·³è¿‡\n",
    "    (414,415),  # MM_MTR       (415) Maternal Transfusion\n",
    "    (415,416),  # MM_PLAC      (416) Perineal Laceration\n",
    "    (416,417),  # MM_RUPT      (417) Ruptured Uterus\n",
    "    (417,418),  # MM_UHYST     (418) Unplanned Hysterectomy\n",
    "    (418,419),  # MM_AICU    (419) Admit to Intensive Care\n",
    "    # 420 filler è·³è¿‡\n",
    "    (420,421),  # F_MM_MTR   (421) Reporting Flag for Maternal Transfusion\n",
    "    (421,422),  # F_MM_PLAC  (422) Reporting Flag for Perineal Laceration\n",
    "    (422,423),  # F_MM_RUPT  (423) Reporting Flag for Ruptured Uterus\n",
    "    (423,424),  # F_MM_UHYST (424) Reporting Flag for Unplanned Hysterectomy\n",
    "    (424,425),  # F_MM_AICU  (425) Reporting Flag for Admission to Intensive Care\n",
    "    # 426 filler è·³è¿‡\n",
    "    (426,427),  # NO_MMORB   (427) No Maternal Morbidity Reported\n",
    "    # 428â€“432 filler è·³è¿‡\n",
    "    (432,433),  # ATTEND     (433) Attendant at Birth\n",
    "    (433,434),  # MITRAN     (434) Mother Transferred\n",
    "    (434,435),  # PAY        (435) Payment Source for Delivery\n",
    "    # === æœ¬é¡µç»§ç»­ï¼ˆ436â€“450ï¼‰: Payment Recode + APGAR ===\n",
    "    (435,436),  # PAY_REC   (436) Payment Recode\n",
    "    (436,437),  # F_PAY     (437) Reporting Flag for Source of Payment\n",
    "    (437,438),  # F_PAY_REC (438) Reporting Flag for Payment Recode\n",
    "    # 439â€“443 filler è·³è¿‡\n",
    "    (443,445),  # APGAR5    (444â€“445) Five Minute APGAR Score\n",
    "    (445,446),  # APGAR5R   (446) Five Minute APGAR Recode\n",
    "    (446,447),  # F_APGAR5  (447) Reporting Flag for Five Minute APGAR\n",
    "    (447,449),  # APGAR10   (448â€“449) Ten Minute APGAR Score\n",
    "    (449,450),  # APGAR10R  (450) Ten Minute APGAR Recode\n",
    "    # 451â€“453 filler è·³è¿‡\n",
    "    (453,454),  # DPLURAL   (454) Plurality Recode\n",
    "    # 455 filler è·³è¿‡\n",
    "    (455,456),  # IMP_PLUR  (456) Plurality Imputed\n",
    "    # 457â€“458 filler è·³è¿‡\n",
    "    (458,459),  # SETORDER_R (459) Set Order Recode\n",
    "    # 460â€“474 filler è·³è¿‡\n",
    "    (474,475),  # SEX       (475) Sex of Infant\n",
    "    (475,476),  # IMP_SEX   (476) Imputed Sex\n",
    "    (476,478),  # DLMP_MM   (477â€“478) Last Normal Menses Month\n",
    "    # 479â€“480 filler è·³è¿‡\n",
    "    (480,484),  # DLMP_YY    (481â€“484) Last Normal Menses Year\n",
    "    # 485â€“487 filler è·³è¿‡\n",
    "    (487,488),  # COMPGST_IMP (488) Combined Gestation Imputation Flag\n",
    "    (488,489),  # OBGEST_FLG  (489) Obstetric Estimate of Gestation Used Flag\n",
    "    (489,491),  # COMBGEST    (490â€“491) Combined Gestation â€“ Detail in Weeks\n",
    "    (491,493),  # GESTREC10   (492â€“493) Combined Gestation Recode 10\n",
    "    (493,494),  # GESTREC3    (494) Combined Gestation Recode 3\n",
    "    # 495â€“497 filler è·³è¿‡\n",
    "    (497,498),  # LMPUSED     (498) Combined Gestation Used Flag\n",
    "    (498,500),  # OEGest_Comb (499â€“500) Obstetric Estimate Edited (weeks)\n",
    "    (500,502),  # OEGest_R10  (501â€“502) Obstetric Estimate Recode 10\n",
    "    # === æœ¬é¡µç»§ç»­ï¼ˆ503â€“518ï¼‰: Birth Weight + Abnormal Newborn Conditions ===\n",
    "    (502,503),   # OEGest_R3 (503) Obstetric Estimate Recode 3\n",
    "    (503,507),   # DBWT      (504â€“507) Birth Weight â€“ Detail in Grams (Edited)\n",
    "    # 508 filler è·³è¿‡\n",
    "    (508,510),   # BWTR12    (509â€“510) Birth Weight Recode 12\n",
    "    (510,511),   # BWTR4     (511) Birth Weight Recode 4\n",
    "    # 512â€“516 filler è·³è¿‡\n",
    "    (516,517),   # AB_AVEN1  (517) Assisted Ventilation (immediate)\n",
    "    (517,518),   # AB_AVEN6  (518) Assisted Ventilation > 6 hrs\n",
    "    # === æœ¬é¡µç»§ç»­ï¼ˆ519â€“531ï¼‰: Abnormal Conditions of the Newborn ===\n",
    "    (518,519),  # AB_NICU    (519) Admission to NICU\n",
    "    (519,520),  # AB_SURF    (520) Surfactant\n",
    "    (520,521),  # AB_ANTI    (521) Antibiotics for Newborn\n",
    "    (521,522),  # AB_SEIZ    (522) Seizures\n",
    "    # 523 filler è·³è¿‡\n",
    "    (523,524),  # F_AB_VENT   (524) Reporting Flag for Assisted Ventilation (immediate)\n",
    "    (524,525),  # F_AB_VENT6  (525) Reporting Flag for Assisted Ventilation >6 hrs\n",
    "    (525,526),  # F_AB_NIUC   (526) Reporting Flag for Admission to NICU\n",
    "    (526,527),  # F_AB_SURFAC (527) Reporting Flag for Surfactant\n",
    "    (527,528),  # F_AB_ANTIBIO (528) Reporting Flag for Antibiotics\n",
    "    (528,529),  # F_AB_SEIZ   (529) Reporting Flag for Seizures\n",
    "    # 530 filler è·³è¿‡\n",
    "    (530,531),  # NO_ABNORM   (531) No Abnormal Conditions Checked\n",
    "    # 532â€“536 filler è·³è¿‡\n",
    "    (536,537),  # CA_ANEN   (537) Anencephaly\n",
    "    # === æœ¬é¡µç»§ç»­ï¼ˆ537â€“548ï¼‰: Congenital Anomalies of the Newborn ===\n",
    "    (537,538),  # CA_MNSB   (538) Meningomyelocele / Spina Bifida\n",
    "    (538,539),  # CA_CCHD   (539) Cyanotic Congenital Heart Disease\n",
    "    (539,540),  # CA_CDH    (540) Congenital Diaphragmatic Hernia\n",
    "    (540,541),  # CA_OMPH   (541) Omphalocele\n",
    "    (541,542),  # CA_GAST   (542) Gastroschisis\n",
    "    (542,543),  # F_CA_ANEN  (543) Reporting Flag for Anencephaly\n",
    "    (543,544),  # F_CA_MENIN (544) Reporting Flag for Meningomyelocele/Spina Bifida\n",
    "    (544,545),  # F_CA_HEART (545) Reporting Flag for Congenital Heart Disease\n",
    "    (545,546),  # F_CA_HERNIA (546) Reporting Flag for Congenital Diaphragmatic Hernia\n",
    "    (546,547),  # F_CA_OMPHA  (547) Reporting Flag for Omphalocele\n",
    "    (547,548),  # F_CA_GASTRO (548) Reporting Flag for Gastroschisis\n",
    "    # === æœ¬é¡µç»§ç»­ï¼ˆ549â€“561ï¼‰: Congenital Anomalies (continued) ===\n",
    "    (548,549),  # CA_LIMB    (549) Limb Reduction Defect\n",
    "    (549,550),  # CA_CLEFT   (550) Cleft Lip with/without Cleft Palate\n",
    "    (550,551),  # CA_CLPAL   (551) Cleft Palate alone\n",
    "    (551,552),  # CA_DOWN    (552) Down Syndrome\n",
    "    (552,553),  # CA_DISOR   (553) Suspected Chromosomal Disorder\n",
    "    (553,554),  # CA_HYPO    (554) Hypospadias\n",
    "    (554,555),  # F_CA_LIMB   (555) Reporting Flag for Limb Reduction Defect\n",
    "    (555,556),  # F_CA_CLEFTLP (556) Reporting Flag for Cleft Lip\n",
    "    (556,557),  # F_CA_CLEFT   (557) Reporting Flag for Cleft Palate\n",
    "    (557,558),  # F_CA_DOWNS   (558) Reporting Flag for Down Syndrome\n",
    "    (558,559),  # F_CA_CHROM   (559) Reporting Flag for Suspected Chromosomal Disorder\n",
    "    (559,560),  # F_CA_HYPOS   (560) Reporting Flag for Hypospadias\n",
    "    (560,561),  # NO_CONGEN    (561) No Congenital Anomalies Checked\n",
    "    # === æœ¬é¡µç»§ç»­ï¼ˆ567â€“570ï¼‰: Infant Outcomes ===\n",
    "    (566,567),  # ITRAN   (567) Infant Transferred\n",
    "    (567,568),  # ILIVE   (568) Infant Living at Time of Report\n",
    "    (568,569),  # BFED    (569) Infant Breastfed at Discharge\n",
    "    (569,570),  # F_BFED  (570) Reporting Flag for Breastfed at Discharge\n",
    "    # 571â€“1330 filler è·³è¿‡\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "colnames = [\n",
    "    \"DOB_YY\",\"DOB_MM\",\"DOB_TT\",\"DOB_WK\",\"BFACIL\",\"BFACIL3\",\n",
    "    \"MAGE_IMPFLG\",\"MAGE_REPFLG\",\"MAGER\",\"MAGER14\",\"MAGER9\",\n",
    "    \"MBSTATE_REC\",\"RESTATUS\",\"MRACE31\",\"MRACE6\",\"MRACE15\",\"MBRACE\",\"MRACEIMP\",\n",
    "    \"MHISPX\",\"MHISP_R\",\"F_MHISP\",\"MRACEHISP\",\n",
    "    \"MAR_P\",\"DMAR\",\"MAR_IMP\",\"F_MAR_P\",\n",
    "    \"MEDUC\",\"F_MEDUC\",\"FAGERPT_FLG\",\"FAGECOMB\",\"FAGEREC11\",\"FRACE31\",\"FRACE6\",\"FRACE15\",\n",
    "    \"FHISPX\",\"FHISP_R\",\"F_FHISP\",\"FRACEHISP\",\"FEDUC\",\"F_FEDUC\",\n",
    "    \"PRIORLIVE\",\"PRIORDEAD\",\"PRIORTERM\",\"LBO_REC\",\"TBO_REC\",\n",
    "    \"ILLB_R\",\"ILLB_R11\",\"ILOP_R\",\"ILOP_R11\",\"ILP_R\",\"ILP_R11\",\n",
    "    \"PRECARE\",\"F_MPCB\",\"PRECARE5\",\"PREVIS\",\"PREVIS_REC\",\"F_TPCV\",\n",
    "    \"WIC\",\"F_WIC\",\"CIG_0\",\"CIG_1\",\"CIG_2\",\"CIG_3\",\n",
    "    \"CIG0_R\",\"CIG1_R\",\"CIG2_R\",\"CIG3_R\",\n",
    "    \"F_CIGS_0\",\"F_CIGS_1\",\"F_CIGS_2\",\"F_CIGS_3\",\n",
    "    \"CIG_REC\",\"F_TOBACO\",\n",
    "    \"M_HT_IN\",\"F_M_HT\",\"BMI\",\n",
    "    \"BMI_R\",\"PWGT_R\",\"F_PWGT\",\"DWGT_R\",\"F_DWGT\",\"WTGAIN\",\"WTGAIN_REC\",\"F_WTGAIN\",\n",
    "    \"RF_PDIAB\",\"RF_GDIAB\",\"RF_PHYPE\",\"RF_GHYPE\",\"RF_EHYPE\",\"RF_PPTTERM\",\n",
    "    \"F_RF_PDIAB\",\"F_RF_GDIAB\",\"F_RF_PHYPER\",\"F_RF_GHYPER\",\"F_RF_ECLAMP\",\"F_RF_PPB\",\n",
    "    \"RF_INFTR\",\n",
    "    \"RF_FEDRG\",\"RF_ARTEC\",\"F_RF_INFT\",\"F_RF_INF_DRG\",\"F_RF_INF_ART\",\n",
    "    \"RF_CESAR\",\"RF_CESARN\",\"F_RF_CESAR\",\"F_RF_NCESAR\",\"NO_RISKS\",\n",
    "    \"IP_GON\",\"IP_SYPH\",\"IP_CHLAM\",\"IP_HEPB\",\"IP_HEPC\",\n",
    "    \"F_IP_GONOR\",\"F_IP_SYPH\",\"F_IP_CHLAM\",\"F_IP_HEPATB\",\"F_IP_HEPATC\",\n",
    "    \"NO_INFEC\",\n",
    "    \"OB_ECVS\",\"OB_ECVF\",\"F_OB_SUCC\",\"F_OB_FAIL\",\n",
    "    \"LD_INDL\",\"LD_AUGM\",\"LD_STER\",\"LD_ANTB\",\"LD_CHOR\",\n",
    "    \"LD_ANES\",\n",
    "    \"F_LD_INDL\",\"F_LD_AUGM\",\"F_LD_STER\",\"F_LD_ANTB\",\"F_LD_CHOR\",\"F_LD_ANES\",\n",
    "    \"NO_LBRDLV\",\n",
    "    \"ME_PRES\",\"ME_ROUT\",\"ME_TRIAL\",\n",
    "    \"F_ME_PRES\",\"F_ME_ROUT\",\"F_ME_TRIAL\",\n",
    "    \"RDMETH_REC\",\"DMETH_REC\",\"F_DMETH_REC\",\n",
    "    \"MM_MTR\",\"MM_PLAC\",\"MM_RUPT\",\"MM_UHYST\",\n",
    "    \"MM_AICU\",\n",
    "    \"F_MM_MTR\",\"F_MM_PLAC\",\"F_MM_RUPT\",\"F_MM_UHYST\",\"F_MM_AICU\",\n",
    "    \"NO_MMORB\",\n",
    "    \"ATTEND\",\"MITRAN\",\"PAY\",\n",
    "    \"PAY_REC\",\"F_PAY\",\"F_PAY_REC\",\n",
    "    \"APGAR5\",\"APGAR5R\",\"F_APGAR5\",\"APGAR10\",\"APGAR10R\",\n",
    "    \"DPLURAL\",\"IMP_PLUR\",\"SETORDER_R\",\n",
    "    \"SEX\",\"IMP_SEX\",\"DLMP_MM\",\n",
    "    \"DLMP_YY\",\"COMPGST_IMP\",\"OBGEST_FLG\",\"COMBGEST\",\"GESTREC10\",\"GESTREC3\",\n",
    "    \"LMPUSED\",\"OEGest_Comb\",\"OEGest_R10\",\n",
    "    \"OEGest_R3\",\"DBWT\",\"BWTR12\",\"BWTR4\",\"AB_AVEN1\",\"AB_AVEN6\",\n",
    "    \"AB_NICU\",\"AB_SURF\",\"AB_ANTI\",\"AB_SEIZ\",\n",
    "    \"F_AB_VENT\",\"F_AB_VENT6\",\"F_AB_NIUC\",\"F_AB_SURFAC\",\"F_AB_ANTIBIO\",\"F_AB_SEIZ\",\n",
    "    \"NO_ABNORM\",\n",
    "    \"CA_ANEN\",\"CA_MNSB\",\"CA_CCHD\",\"CA_CDH\",\"CA_OMPH\",\"CA_GAST\",\n",
    "    \"F_CA_ANEN\",\"F_CA_MENIN\",\"F_CA_HEART\",\"F_CA_HERNIA\",\"F_CA_OMPHA\",\"F_CA_GASTRO\",\n",
    "    \"CA_LIMB\",\"CA_CLEFT\",\"CA_CLPAL\",\"CA_DOWN\",\"CA_DISOR\",\"CA_HYPO\",\n",
    "    \"F_CA_LIMB\",\"F_CA_CLEFTLP\",\"F_CA_CLEFT\",\"F_CA_DOWNS\",\"F_CA_CHROM\",\"F_CA_HYPOS\",\n",
    "    \"NO_CONGEN\",\n",
    "    \"ITRAN\",\"ILIVE\",\"BFED\",\"F_BFED\"\n",
    "]\n",
    "\n",
    "\n",
    "# Parquet\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ==== è·¯å¾„è®¾ç½® ====\n",
    "file_path = \"/Users/muyuanchen/Desktop/NIH_research/Nat2018PublicUS.c20190509.r20190717.txt\"\n",
    "out_dir = \"/Users/muyuanchen/Desktop/NIH_research/data/processed\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# ä½ å‰é¢å·²ç»å®šä¹‰å¥½çš„ colspecs å’Œ colnames\n",
    "# è¿™é‡Œç›´æ¥å¼•ç”¨ colspecs, colnames\n",
    "\n",
    "# ==== åˆ†å—è¯»å– & ä¿å­˜ parquet ====\n",
    "chunksize = 200000   # æ¯æ¬¡ 20 ä¸‡è¡Œï¼Œå¯ä»¥æ ¹æ®å†…å­˜è°ƒæ•´\n",
    "i = 0\n",
    "\n",
    "fwf_iter = pd.read_fwf(\n",
    "    file_path,\n",
    "    colspecs=colspecs,\n",
    "    names=colnames,\n",
    "    dtype=str,        # æ‰€æœ‰åˆ—æŒ‰å­—ç¬¦ä¸²è¯»å–\n",
    "    na_filter=False,  # ç¦æ­¢ç©ºæ ¼è‡ªåŠ¨å˜ NaN\n",
    "    chunksize=chunksize\n",
    ")\n",
    "\n",
    "for chunk in fwf_iter:\n",
    "    # å¯é€‰ï¼šå»æ‰é¦–å°¾ç©ºæ ¼\n",
    "    chunk = chunk.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    \n",
    "    # ä¿å­˜ parquetï¼ˆä¿æŒå­—ç¬¦ä¸²ç±»å‹ï¼‰\n",
    "    out_path = os.path.join(out_dir, f\"nat2018_part_{i}.parquet\")\n",
    "    chunk.to_parquet(out_path, engine=\"pyarrow\", index=False)\n",
    "    print(f\"âœ… Saved {out_path} with {len(chunk)} rows\")\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"ğŸ‰ å…¨é‡æ•°æ®å·²æˆåŠŸè½¬æ¢ä¸º Parquetï¼\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# âœ… ç”¨æ›´ç¨³å®šçš„è·¯å¾„\n",
    "os.environ[\"JAVA_HOME\"] = \"/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "\n",
    "# âœ… æ˜¾å¼æŒ‡å®š local[*]\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LBW_Analysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"Spark version:\", spark.version)\n",
    "\n",
    "# âœ… æµ‹è¯• parquet è¯»å–\n",
    "df = spark.read.parquet(\"/Users/muyuanchen/Desktop/NIH_research/data/processed/nat2018_part_*.parquet\")\n",
    "print(\"æ€»è¡Œæ•°:\", df.count())\n",
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c08a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, count, isnan, regexp_extract\n",
    "import re\n",
    "\n",
    "# === Step 1: æ‰¾è¡ç”Ÿåˆ— ===\n",
    "derived_cols = []\n",
    "for c in df.columns:\n",
    "    if (\n",
    "        c.startswith(\"F_\") or\n",
    "        \"_R\" in c or \"REC\" in c or\n",
    "        (re.match(r\".*\\d+$\", c) and not c.endswith((\"YY\",\"MM\",\"TT\")))\n",
    "    ):\n",
    "        derived_cols.append(c)\n",
    "\n",
    "print(f\"åŸå§‹æ€»åˆ—æ•°: {len(df.columns)}\")\n",
    "print(f\"è¯†åˆ«å‡ºçš„è¡ç”Ÿåˆ—æ•°: {len(derived_cols)}\")\n",
    "\n",
    "# === Step 2: åˆ é™¤è¡ç”Ÿåˆ— ===\n",
    "df_drop_dev = df.drop(*derived_cols)\n",
    "print(f\"åˆ é™¤è¡ç”Ÿåˆ—å: {len(df.columns)} â†’ {len(df_drop_dev.columns)} åˆ—\")\n",
    "\n",
    "# === Step 3: åˆ é™¤ç¼ºå¤±æ¯”ä¾‹è¶…è¿‡90%çš„åˆ— ===\n",
    "total_rows = df_drop_dev.count()\n",
    "nan_ratios = {}\n",
    "for c in df_drop_dev.columns:\n",
    "    nan_count = df_drop_dev.filter((col(c).isNull()) | (col(c) == \"\")).count()\n",
    "    nan_ratios[c] = nan_count / total_rows\n",
    "\n",
    "cols_to_drop = [c for c, ratio in nan_ratios.items() if ratio > 0.9]\n",
    "df_no_high_missing = df_drop_dev.drop(*cols_to_drop)\n",
    "print(f\"åˆ é™¤ç¼ºå¤±æ¯”ä¾‹ > 90% çš„åˆ—: {len(df_drop_dev.columns)} â†’ {len(df_no_high_missing.columns)} åˆ— (å…±åˆ é™¤ {len(cols_to_drop)} åˆ—)\")\n",
    "\n",
    "# === Step 4: åˆ é™¤å…¨ NaN çš„åˆ— ===\n",
    "all_nan_cols = []\n",
    "for c in df_no_high_missing.columns:\n",
    "    if df_no_high_missing.filter((col(c).isNotNull()) & (col(c) != \"\")).count() == 0:\n",
    "        all_nan_cols.append(c)\n",
    "\n",
    "df_no_nan_cols = df_no_high_missing.drop(*all_nan_cols)\n",
    "print(f\"åˆ é™¤å…¨ NaN çš„åˆ—: {len(df_no_high_missing.columns)} â†’ {len(df_no_nan_cols.columns)} åˆ— (å…±åˆ é™¤ {len(all_nan_cols)} åˆ—)\")\n",
    "\n",
    "# === Step 5: åˆ é™¤å« NaN çš„è¡Œ ===\n",
    "before_rows = df_no_nan_cols.count()\n",
    "df_final = df_no_nan_cols.na.drop()\n",
    "after_rows = df_final.count()\n",
    "print(f\"åˆ é™¤å« NaN çš„è¡Œ: {before_rows} â†’ {after_rows} è¡Œ\")\n",
    "\n",
    "print(\"æœ€ç»ˆæ•°æ®ç»´åº¦:\", (df_final.count(), len(df_final.columns)))\n",
    "\n",
    "# === ä¿å­˜ç»“æœ ===\n",
    "output_path = \"/Users/muyuanchen/Desktop/NIH_research/nat2018_cleaned_sparked.csv\"\n",
    "df_final.write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_path)\n",
    "print(f\"å·²ä¿å­˜è‡³: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac08212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "# === è¾“å…¥è·¯å¾„ ===\n",
    "types_csv = \"/Users/muyuanchen/Desktop/NIH_research/nat2018_variable_types_updated.csv\"\n",
    "\n",
    "# === è¯»å…¥ç±»å‹è¡¨ ===\n",
    "df_types = spark.read.option(\"header\", True).csv(types_csv)\n",
    "\n",
    "cat_cols = [row[\"Variable\"] for row in df_types.filter(df_types.Type == \"categorical\").collect()]\n",
    "bin_cols = [row[\"Variable\"] for row in df_types.filter(df_types.Type == \"binary\").collect()]\n",
    "num_cols = [row[\"Variable\"] for row in df_types.filter(df_types.Type == \"numeric\").collect()]\n",
    "\n",
    "# === Step 1: Binary è½¬æ¢ ===\n",
    "BIN_UNK_MAP = {\n",
    "    \"RF_PDIAB\": [\"U\"], \"RF_GDIAB\": [\"U\"], \"RF_PHYPE\": [\"U\"], \"RF_GHYPE\": [\"U\"],\n",
    "    \"RF_EHYPE\": [\"U\"], \"RF_PPTTERM\": [\"U\"], \"RF_INFTR\": [\"U\"], \"RF_FEDRG\": [\"X\",\"U\"],\n",
    "    \"RF_ARTEC\": [\"X\",\"U\"], \"RF_CESAR\": [\"U\"], \"RF_CESARN\": [9],\n",
    "    \"IP_GON\": [\"U\"], \"IP_SYPH\": [\"U\"], \"IP_CHLAM\": [\"U\"], \"IP_HEPB\": [\"U\"], \"IP_HEPC\": [\"U\"],\n",
    "    \"NO_INFEC\": [\"U\"], \"OB_ECVS\": [\"U\"], \"OB_ECVF\": [\"U\"],\n",
    "    \"LD_INDL\": [\"U\"], \"LD_AUGM\": [\"U\"], \"LD_STER\": [\"U\"], \"LD_ANTB\": [\"U\"],\n",
    "    \"LD_CHOR\": [\"U\"], \"LD_ANES\": [\"U\"], \"NO_LBRDLV\": [\"U\"],\n",
    "    \"ME_PRES\": [\"U\"], \"ME_TRIAL\": [\"U\"],\n",
    "    \"MM_MTR\": [\"U\"], \"MM_PLAC\": [\"U\"], \"MM_UHYST\": [\"U\"], \"MM_AICU\": [\"U\"], \"NO_MMORB\": [\"U\"],\n",
    "    \"AB_NICU\": [\"U\"], \"AB_SURF\": [\"U\"], \"AB_ANTI\": [\"U\"], \"AB_SEIZ\": [\"U\"], \"NO_ABNORM\": [\"U\"],\n",
    "    \"CA_ANEN\": [\"U\",\"X\",\"C\",\"P\"], \"CA_MNSB\": [\"U\",\"X\",\"C\",\"P\"], \"CA_CCHD\": [\"U\",\"X\",\"C\",\"P\"],\n",
    "    \"CA_CDH\": [\"U\",\"X\",\"C\",\"P\"], \"CA_OMPH\": [\"U\",\"X\",\"C\",\"P\"], \"CA_GAST\": [\"U\",\"X\",\"C\",\"P\"],\n",
    "    \"CA_LIMB\": [\"U\",\"X\",\"C\",\"P\"], \"CA_CLEFT\": [\"U\",\"X\",\"C\",\"P\"], \"CA_CLPAL\": [\"U\",\"X\",\"C\",\"P\"],\n",
    "    \"CA_DOWN\": [\"U\",\"X\",\"C\",\"P\"], \"CA_DISOR\": [\"U\",\"X\",\"C\",\"P\"], \"CA_HYPO\": [\"U\",\"X\",\"C\",\"P\"],\n",
    "    \"NO_CONGEN\": [\"U\"], \"ITRAN\": [\"U\"], \"ILIVE\": [\"U\"], \"BFED\": [\"U\"],\n",
    "    \"WIC\": [\"U\"], \"SEX\": [], \"DMAR\": [\"U\"], \"MAR_P\": [\"U\"]\n",
    "}\n",
    "\n",
    "for col in bin_cols:\n",
    "    if col in df_final.columns:\n",
    "        unk_vals = BIN_UNK_MAP.get(col, [])\n",
    "        df_final = df_final.withColumn(\n",
    "            col,\n",
    "            F.when(F.col(col).isin(*unk_vals), None)\n",
    "             .when(F.upper(F.col(col)).isin(\"Y\",\"YES\",\"M\",\"C\",\"P\",\"1\"), 1)\n",
    "             .when(F.upper(F.col(col)).isin(\"N\",\"NO\",\"F\",\"0\",\"2\"), 0)\n",
    "             .otherwise(F.col(col).cast(\"int\"))\n",
    "        )\n",
    "\n",
    "# === Step 2: Categorical One-Hot ===\n",
    "UNK_MAP = {\n",
    "    \"MEDUC\": [9], \"FEDUC\": [9], \"PAY\": [9], \"ATTEND\": [9],\n",
    "    \"BFACIL\": [9], \"RESTATUS\": [9], \"MBRACE\": [99],\n",
    "    \"MRACEHISP\": [8], \"FRACEHISP\": [8], \"FHISPX\": [9],\n",
    "    \"MHISPX\": [6, 9], \"DPLURAL\": [9], \"FAGECOMB\": [99],\n",
    "}\n",
    "\n",
    "indexers, encoders = [], []\n",
    "for col in cat_cols:\n",
    "    if col in df_final.columns:\n",
    "        unk_vals = UNK_MAP.get(col, [])\n",
    "        df_final = df_final.withColumn(\n",
    "            col,\n",
    "            F.when(F.col(col).isin(*unk_vals), \"Unknown\").otherwise(F.col(col).cast(\"string\"))\n",
    "        )\n",
    "        indexers.append(StringIndexer(inputCol=col, outputCol=col+\"_idx\", handleInvalid=\"keep\"))\n",
    "        encoders.append(OneHotEncoder(inputCol=col+\"_idx\", outputCol=col+\"_oh\"))\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders)\n",
    "df_encoded = pipeline.fit(df_final).transform(df_final)\n",
    "\n",
    "# === Step 3: å±•å¼€ OneHot å‘é‡æˆå¤šåˆ— ===\n",
    "for col in cat_cols:\n",
    "    oh_col = col + \"_oh\"\n",
    "    if oh_col in df_encoded.columns:\n",
    "        df_encoded = df_encoded.withColumn(oh_col+\"_arr\", vector_to_array(oh_col))\n",
    "        size = df_encoded.select(F.size(oh_col+\"_arr\")).first()[0]\n",
    "        for i in range(size):\n",
    "            df_encoded = df_encoded.withColumn(f\"{col}_{i}\", F.col(oh_col+\"_arr\")[i])\n",
    "\n",
    "# === Step 4: åˆ é™¤æ³„æ¼åˆ— ===\n",
    "drop_cols = [\n",
    "    \"DBWT\",\"APGAR5R\",\"APGAR10R\",\"AB_NICU\",\"AB_SURF\",\"AB_ANTI\",\"AB_SEIZ\",\"NO_ABNORM\",\n",
    "    \"CA_ANEN\",\"CA_MNSB\",\"CA_CCHD\",\"CA_CDH\",\"CA_OMPH\",\"CA_GAST\",\"CA_LIMB\",\"CA_CLEFT\",\n",
    "    \"CA_CLPAL\",\"CA_DOWN\",\"CA_DISOR\",\"CA_HYPO\",\"NO_CONGEN\",\"MM_MTR\",\"MM_PLAC\",\"MM_UHYST\",\n",
    "    \"MM_AICU\",\"NO_MMORB\",\"ILIVE\",\"DOB_TT\",\"DOB_WK\",\"COMBGEST\",\"LD_STER\",\"LD_INDL\",\n",
    "    \"MRACEHISP_3.0\",\"FRACEHISP_3.0\",\"DLMP_MM\"\n",
    "]\n",
    "df_final_model = df_encoded.drop(*[c for c in drop_cols if c in df_encoded.columns])\n",
    "\n",
    "# === è¾“å‡ºæ£€æŸ¥ ===\n",
    "print(\"æœ€ç»ˆç»´åº¦:\", (df_final_model.count(), len(df_final_model.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/Users/muyuanchen/Desktop/NIH_research/df_final_model.parquet\"\n",
    "df_final_model.write.mode(\"overwrite\").parquet(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac678387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/18 16:20:08 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "25/09/18 16:20:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/09/18 16:20:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "25/09/18 16:20:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ridge å›å½’ (PySpark) ç»“æœ\n",
      "RMSE: 487.272008852158\n",
      "RÂ²: 0.3222833192823549\n"
     ]
    }
   ],
   "source": [
    "# ridge regression\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# === 1. å¯åŠ¨ SparkSession ===\n",
    "spark = SparkSession.builder.appName(\"NIH_RidgeRegression\").getOrCreate()\n",
    "\n",
    "# === 2. è¯»å…¥æ•°æ®ï¼ˆæ³¨æ„ï¼šä½ å‰é¢å·²ç» drop è¿‡æ³„æ¼åˆ—äº†ï¼‰===\n",
    "df = spark.read.csv(\n",
    "    \"/Users/muyuanchen/Desktop/NIH_research/nat2018_model_matrix_final.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "for old_col in df.columns:\n",
    "    new_col = old_col.replace(\".\", \"_\")\n",
    "    df = df.withColumnRenamed(old_col, new_col)\n",
    "\n",
    "\n",
    "# === 3. ç›®æ ‡å˜é‡ & ç‰¹å¾åˆ— ===\n",
    "target_col = \"DBWT\"\n",
    "feature_cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "# === 4. ç¼ºå¤±å€¼å¡«å…… ===\n",
    "df = df.fillna(0)\n",
    "\n",
    "# === 5. ç»„è£…ç‰¹å¾å‘é‡ ===\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_unscaled\")\n",
    "scaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\")\n",
    "\n",
    "# === 6. Ridge å›å½’ (L2 æ­£åˆ™åŒ–) ===\n",
    "ridge = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=target_col,\n",
    "    regParam=1.0,        # Î±\n",
    "    elasticNetParam=0.0  # 0 = Ridge\n",
    ")\n",
    "\n",
    "# === 7. Pipeline ===\n",
    "pipeline = Pipeline(stages=[assembler, scaler, ridge])\n",
    "\n",
    "# === 8. åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# === 9. è®­ç»ƒæ¨¡å‹ ===\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# === 10. é¢„æµ‹ ===\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# === 11. è¯„ä¼° ===\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=target_col, predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ")\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=target_col, predictionCol=\"prediction\", metricName=\"r2\"\n",
    ")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(\"âœ… Ridge å›å½’ (PySpark) ç»“æœ\")\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"RÂ²:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82ac713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {1: 8.787346221441124, 0: 0.5301664722722935}\n",
      "AUC: 0.9466032608695701\n",
      "\n",
      "Detailed classification report:\n",
      "Class 0:\n",
      "  Precision = 0.997\n",
      "  Recall    = 0.838\n",
      "  F1 Score  = 0.911\n",
      "  Support   = 1840\n",
      "------------------------------\n",
      "Class 1:\n",
      "  Precision = 0.242\n",
      "  Recall    = 0.950\n",
      "  F1 Score  = 0.385\n",
      "  Support   = 100\n",
      "------------------------------\n",
      "Overall Accuracy: 0.8438144329896907\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# === 1. å¯åŠ¨ SparkSession ===\n",
    "spark = SparkSession.builder.appName(\"NIH_LogisticRegression_CSV_Report\").getOrCreate()\n",
    "\n",
    "# === 2. è¯»å…¥ CSV æ•°æ® ===\n",
    "df = spark.read.csv(\n",
    "    \"/Users/muyuanchen/Desktop/NIH_research/nat2018_model_matrix_final.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "# é¿å…åˆ—åæœ‰ç‚¹å·\n",
    "for old_col in df.columns:\n",
    "    new_col = old_col.replace(\".\", \"_\")\n",
    "    df = df.withColumnRenamed(old_col, new_col)\n",
    "\n",
    "# === 3. æ ‡ç­¾åˆ— & ç‰¹å¾åˆ— ===\n",
    "target_col = \"DBWT\"\n",
    "feature_cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "# äºŒåˆ†ç±»æ ‡ç­¾ï¼šä½ä½“é‡ (<2500g) â†’ label=1\n",
    "df = df.withColumn(\"label\", (col(\"DBWT\") < 2500).cast(\"int\"))\n",
    "\n",
    "# === 4. ç¼ºå¤±å€¼å¡«å…… ===\n",
    "df = df.fillna(0)\n",
    "\n",
    "# === 5. è®¡ç®— class weight ===\n",
    "class_counts = df.groupBy(\"label\").count().collect()\n",
    "count_dict = {row[\"label\"]: row[\"count\"] for row in class_counts}\n",
    "total_count = sum(count_dict.values())\n",
    "num_classes = len(count_dict)\n",
    "\n",
    "# å¸¸è§åšæ³•ï¼š total_count / (num_classes * count(label))\n",
    "class_weights = {label: total_count / (num_classes * count) for label, count in count_dict.items()}\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# æ–°å»ºæƒé‡åˆ—\n",
    "df = df.withColumn(\n",
    "    \"classWeight\",\n",
    "    when(col(\"label\") == 0, class_weights[0]).otherwise(class_weights[1])\n",
    ")\n",
    "\n",
    "# === 6. ç‰¹å¾ç»„è£… + æ ‡å‡†åŒ– ===\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_unscaled\")\n",
    "scaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\")\n",
    "\n",
    "# === 7. Logistic Regression with class weight + lower threshold ===\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    weightCol=\"classWeight\",  # å¹³è¡¡æƒé‡\n",
    "    maxIter=50,\n",
    "    threshold=0.3             # è°ƒä½é˜ˆå€¼\n",
    ")\n",
    "\n",
    "# === 8. Pipeline ===\n",
    "pipeline = Pipeline(stages=[assembler, scaler, log_reg])\n",
    "\n",
    "# === 9. åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# === 10. è®­ç»ƒ ===\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# === 11. é¢„æµ‹ ===\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# === 12. AUC ===\n",
    "evaluator_auc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\"\n",
    ")\n",
    "auc = evaluator_auc.evaluate(predictions)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# === 13. è½¬æˆ RDDï¼Œç®—æ¯ä¸ª class çš„ precision / recall / f1 ===\n",
    "predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd.map(lambda x: (float(x[0]), float(x[1])))\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "unique_labels = predictionAndLabels.map(lambda x: x[1]).distinct().collect()\n",
    "print(\"\\nDetailed classification report:\")\n",
    "for label in sorted(unique_labels):\n",
    "    print(f\"Class {int(label)}:\")\n",
    "    print(f\"  Precision = {metrics.precision(label):.3f}\")\n",
    "    print(f\"  Recall    = {metrics.recall(label):.3f}\")\n",
    "    print(f\"  F1 Score  = {metrics.fMeasure(label):.3f}\")\n",
    "    print(f\"  Support   = {predictionAndLabels.filter(lambda x: x[1] == label).count()}\")\n",
    "    print(\"-\"*30)\n",
    "\n",
    "# === 14. Overall Accuracy ===\n",
    "print(\"Overall Accuracy:\", metrics.accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark351",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
